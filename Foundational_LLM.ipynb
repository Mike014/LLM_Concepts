{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Large Language Models (LLMs)**\n",
    "\n",
    "## **Large Language Models and Transformer Architecture**\n",
    "#### **What is a Language Model**\n",
    "A language model **estimates the probability that a sequence of words will appear**. Given an initial text, it **predicts the most likely subsequent terms**. The simplest models **are based on n-grams**, while **modern models use advanced neural networks**, especially **transformers**.\n",
    "\n",
    "#### **RNN to Transformer**\n",
    "Before transformers, **RNNs (e.g., LSTM and GRU)** were used to **process sequences sequentially**, but they **were difficult to parallelize and suffered from the problem of vain gradients**. Transformer have revolutionized the field thanks to **self-attention**,**which allows the entire sequence to be processed in parallel**, also modeling long-term dependencies more effectively.\n",
    "\n",
    "### **The Transformer**\n",
    "\n",
    "#### **Basic architecture**\n",
    "Introduced by Google in 2017 for machine translation, the **transformer** is composed of two main blocks:\n",
    "- **Encoder**: **processes the input** text and creates a contextual representation.\n",
    "- **Decoder**: **generates the output** text autoregressively from this representation.\n",
    "\n",
    "#### **Fundamental components**\n",
    "1. **Input Embedding**: each word is converted into a high-dimensional vector (embedding), combined with **positional encoding** to maintain word order.\n",
    "2. **Multi-head Attention**: central mechanism that allows the model to focus on different parts of the sequence via multiple parallel attention “heads”.\n",
    "3. **Self-Attention**: calculates the relative importance between words using **query (Q)**, **key (K)** and **value (V)** vectors.\n",
    "4. **Layer Normalization & Residuals**: stabilize and speed up training through normalization and direct connections between inputs and outputs of a layer.\n",
    "5. **Feedforward Layer**: applies nonlinear transformations to each position of the sequence.\n",
    "6. **Decoder (with masked attention)**: generates the output one token at a time, without accessing future tokens to preserve autoregression.\n",
    "\n",
    "### **Mixture of Experts (MoE)**\n",
    "\n",
    "The Mixture of Experts (MoE) is an **architecture** that combines **multiple** specialized **models**, called **“experts,”** to **address complex tasks more efficiently and effectively**.\n",
    "\n",
    "#### **Main Components**\n",
    "- **Experts**: specialized models (often transformers), each trained to **handle a specific subset of the task or data**.\n",
    "- **Gating Network (Router)**: decides **which experts to send each piece of input to**. **Computes a probability** distribution over all experts, **establishing the “weight**” of each expert’s contribution.\n",
    "- **Combination Mechanism**: **combines the expert responses**, weighting them based on the distribution provided by the router, to obtain a final optimized prediction.\n",
    "\n",
    "### **Large Reasoning Models**\n",
    "\n",
    "**Advanced reasoning models** do not rely only on the power of the Transformer, but **integrate architectural techniques**, **prompting strategies** and specialized **training methods**.\n",
    "\n",
    "#### Prompting Techniques\n",
    "- **Chain-of-Thought**: guides the model to **reason** step by step.\n",
    "- **Tree-of-Thoughts**: explores **multiple logical paths and selects** the best one.\n",
    "- **Least-to-Most**: **tackles problems in order of increasing difficulty**, reusing answers.\n",
    "\n",
    "#### Improving logical capabilities\n",
    "- **Fine-tuning on reasoning datasets** (logic, mathematics, common sense).\n",
    "- **Instruction tuning**: trains the model to follow instructions in natural language.\n",
    "- **RLHF**: improves consistency and quality by rewarding more useful answers.\n",
    "\n",
    "#### Support Techniques\n",
    "- **Knowledge distillation**: transfer skills from large models to lightweight models.\n",
    "- **Beam Search & Temperature**: improve output quality.\n",
    "- **RAG**: integrate data from external sources to enrich answers.\n",
    "\n",
    "### **Training Transformers**\n",
    "\n",
    "#### Data prep\n",
    "- Cleaning → Tokenization → Split between training/testing.\n",
    "\n",
    "#### Training\n",
    "- Input → Output → **loss** calculation → Backpropagation → Weight optimization.\n",
    "\n",
    "#### Architectures\n",
    "- **Decoder-only** (GPT): sequential prediction.\n",
    "- **Encoder-only** (BERT): masked input reconstruction.\n",
    "- **Encoder-Decoder** (T5): tasks such as translation, synthesis, QA.\n",
    "\n",
    "#### Context Length\n",
    "More tokens = more context → but also more resources. Balance is needed.\n",
    "\n",
    "Although Large Language Models are based on mathematics and statistics (neural networks, probability, optimization), **they are not just that**. Their emerging abilities for **reasoning, generalization, and language understanding** come from how they learn through large amounts of data, linguistic examples, and techniques such as *prompting* or *fine-tuning*. Mathematics is the basis, but the resulting behavior **simulates complex cognitive processes**, which cannot be explained with formulas alone.\n",
    "\n",
    "### **Transformer and LLM Evolution**\n",
    "\n",
    "#### **GPT-1 (2018) – OpenAI**\n",
    "- First **decoder-only** based on **unsupervised pre-training** (BooksCorpus).\n",
    "- Introduced the concept of **supervised fine-tuning after pre-training**, making models more generic and adaptable.\n",
    "- Limitations: weak cohesion on long texts, little context memory.\n",
    "\n",
    "#### **BERT – Google**\n",
    "- **Encoder-only**, specialized in **language understanding**, not generation.\n",
    "- Trained with **masked language modeling** and **next sentence prediction**.\n",
    "- Great for: sentiment analysis, QA, NLU.\n",
    "\n",
    "#### **GPT-2**\n",
    "- 1.5B parameters, trained on WebText.\n",
    "- Huge progress in **text coherence** and introduced **zero-shot learning**.\n",
    "\n",
    "#### **GPT-3, 3.5, 4**\n",
    "- GPT-3: 175B parameters, excels at few-shot and zero-shot. Commercial use via API.\n",
    "- InstructGPT: tuning on human data + RLHF → more useful and secure answers.\n",
    "- GPT-4: **multimodal**, 128k tokens, strong on reasoning and complex domains.\n",
    "\n",
    "### **Other main models**\n",
    "\n",
    "#### **LaMDA (Google)**\n",
    "- Focus on fluid and natural conversations. Trained on dialogue data.\n",
    "\n",
    "#### **Gopher (DeepMind)**\n",
    "- 280B parameters. Great at general knowledge, less so on abstract reasoning.\n",
    "\n",
    "#### **GLaM (Google)**\n",
    "- First **sparsely activated** model (Mixture of Experts, 1.2T parameters but only active part for input), efficient and powerful.\n",
    "\n",
    "#### **Chinchilla (DeepMind)**\n",
    "- 70B parameters, but trained on **larger dataset**. Proved that more data matters as much as parameters → new standard for optimal training.\n",
    "\n",
    "### **PaLM Line → Gemini (Google)**\n",
    "\n",
    "#### **PaLM / PaLM 2**\n",
    "- 540B parameters. Trained for **reasoning**, **code**, **translation**, **humor**.\n",
    "- PaLM 2: more efficient, great at coding and QA.\n",
    "\n",
    "#### **Gemini 1.0 → 2.0**\n",
    "- **Multimodal models** (text, images, audio, video).\n",
    "- **Gemini Pro / Ultra / Nano / Flash** for scalable or device-based uses.\n",
    "- **Gemini 1.5 Pro**: context up to 10M tokens, excels in video analysis, code comprehension, multilingual reasoning.\n",
    "- **Gemini 2.0**: improves efficiency, spatial understanding, scientific reasoning. “Flash Thinking” version shows the “thinking process”.\n",
    "\n",
    "### **Relevant open-source models**\n",
    "\n",
    "#### **Gemma (Google)**\n",
    "- Lightweight open-source models, even **multimodal**, optimized for efficiency.\n",
    "- **Gemma 3**: up to 128k tokens, over 140 languages, available in sizes from 1B to 27B.\n",
    "\n",
    "#### **LLaMA (Meta)**\n",
    "- Decoder-only, 7B to 70B parameters.\n",
    "- LLaMA 2-Chat optimized for dialogue, LLaMA 3.2 also supports vision and long context.\n",
    "\n",
    "#### **Mixtral (Mistral AI)**\n",
    "- **Sparse Mixture of Experts** model, uses only 13B of 47B parameters for input.\n",
    "- Excels in **math**, **multilingual** and **code**.\n",
    "\n",
    "### **Advanced Reasoning Oriented Models**\n",
    "\n",
    "#### **OpenAI o1**\n",
    "- Inner Chain of Reasoning (CoT), excels in science, math, competitions (e.g. AIME).\n",
    "\n",
    "#### **DeepSeek**\n",
    "- Pure unsupervised RL model. Uses **Group Relative Policy Optimization (GRPO)** + automatic selection of best outputs to generate its training data. Excellent in math and reasoning tasks.\n",
    "\n",
    "### **Other well-known models**\n",
    "- **Qwen (Alibaba)**: excellent on reasoning and math (up to 72B).\n",
    "- **Yi (01.AI)**: balanced between performance and efficiency.\n",
    "- **Grok (xAI)**: 1M tokens, focus on reasoning and self-correction.\n",
    "- Others: **GPT-NeoX**, **Alpaca**, **Vicuna**, **Falcon**, **PHI**, **DBRX**, **NVLM**, etc.\n",
    "\n",
    "### **Conclusion**\n",
    "Transformer models have evolved from monolithic models to **more modular, multimodal and intelligent architectures**, focusing on efficiency, reasoning, and adaptability. Today, the challenge is to scale while maintaining efficiency and controlling costs, paving the way for more sustainable and accessible models.\n",
    "\n",
    "\n",
    "##### **Comparison**\n",
    "Transformer-based language models have **evolved from encoder-decoder** architectures with millions of parameters **to massive decoder-only** models with billions of parameters and trained on trillions of tokens. This growth has improved performance and fostered emergent behaviors, such as **few-shot** and **zero-shot learning**. However, **limitations persist**: **difficulty with natural dialogues**, **weak mathematical skills**, and **possible biases or toxic responses**. The next section explores how these problems are being addressed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Fine-Tuning of LLMs**\n",
    "\n",
    "After **pre-training** on huge unlabeled datasets, LLMs can be **specialized** via **supervised fine-tuning (SFT)**, improving their effectiveness on specific tasks (e.g. QA, summarization, translations) or desired behaviors (e.g. following instructions, dialoguing, avoiding toxic responses).\n",
    "\n",
    "#### **Fine-Tuning Techniques**\n",
    "- **Instruction tuning**: train the model to follow instructions (e.g. “write a poem”).\n",
    "- **Dialogue tuning**: optimize for multi-turn conversations.\n",
    "- **Safety tuning**: reduce bias and dangerous content.\n",
    "\n",
    "Fine-tuning is much less expensive than pre-training and more data efficient.\n",
    "\n",
    "### **RLHF – Reinforcement Learning from Human Feedback**\n",
    "Advanced technique to **align the model with human preferences**. A **Reward Model** trained on **human feedback** (preferences between two responses) is used. The final model is optimized using RL algorithms (e.g. policy gradient).\n",
    "\n",
    "Variants:\n",
    "- **RLAIF**: uses feedback generated by other models instead of humans.\n",
    "- **DPO**: alternative method that avoids explicit training via RL.\n",
    "\n",
    "These techniques improve the safety, accuracy and utility of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parameter Efficient Fine-Tuning (PEFT)**\n",
    "\n",
    "Full fine-tuning of LLMs is expensive in terms of time and resources. **PEFT** techniques offer an efficient alternative, allowing to adapt large models **training only a small portion of parameters**, while maintaining high performance.\n",
    "\n",
    "#### Main PEFT techniques:\n",
    "- **Adapter**: small modules added to the model; only they update.\n",
    "- **LoRA (Low-Rank Adaptation)**: updates only two lightweight matrices, leaving the original weights unchanged. Versions like **QLoRA** also use quantization for greater efficiency.\n",
    "- **Soft Prompting**: optimized vectors instead of text prompts. They can be just a few tokens and are highly efficient.\n",
    "\n",
    "---\n",
    "\n",
    "**Performance/Cost Comparison**:\n",
    "- **Performance**: Full Fine-Tuning > LoRA > Soft Prompting\n",
    "- **Efficiency and Cost**: Soft Prompting > LoRA > Full Fine-Tuning\n",
    "\n",
    "All PEFT techniques offer a good balance between performance and resources used, making fine-tuning accessible even in resource-constrained environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Prompt Engineering and Using LLMs**\n",
    "\n",
    "The effectiveness of large language models (LLMs) strongly depends on two factors: **prompt engineering** and **sampling techniques**.\n",
    "\n",
    "### **Prompt Engineering**\n",
    "It is the art of building effective inputs (prompts) to obtain desired outputs. It can be used to:\n",
    "- obtain more **factual** answers\n",
    "- stimulate **creativity** (e.g. stories, songs)\n",
    "- guide the model with **clear instructions**, examples, keywords, or formatting\n",
    "\n",
    "There are three main approaches:\n",
    "- **Zero-shot prompting**: provide only the instruction (without examples)\n",
    "- **Few-shot prompting**: include 3–5 examples to help the model\n",
    "- **Chain-of-thought prompting**: guide the model by showing step-by-step reasoning for complex problems\n",
    "\n",
    "These techniques improve the reliability and intelligence of the model on various tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sampling Techniques in LLMs**\n",
    "They are used to control creativity, coherence and diversity of the generated output:\n",
    "\n",
    "- **Greedy Search**: chooses the most probable token. Coherent but predictable outputs.\n",
    "- **Random Sampling**: random selection based on the distribution. Creative, but more chaotic.\n",
    "- **Temperature**: adjusts randomness. Higher values ​​= greater diversity.\n",
    "- **Top-K**: samples only among the K most probable tokens.\n",
    "- **Top-P (nucleus)**: samples among tokens whose probability sum reaches P.\n",
    "- **Best-of-N**: generates N answers and chooses the best one according to a criterion (e.g. logical coherence).\n",
    "\n",
    "### **Evaluation of LLMs in Applications**\n",
    "When moving from a prototype to a real app, a customized evaluation system is needed:\n",
    "\n",
    "- **Evaluation Data**: must reflect real use cases. They can also include production logs or synthetic data.\n",
    "- **Development Context**: Evaluation must include the entire system (e.g. RAG, agents, etc.).\n",
    "- **Definition of “good”**: It is based on practical goals, not just on literal matching with a correct answer.\n",
    "\n",
    "### **Evaluation Methods**\n",
    "- **Traditional**: Compare with ideal answers. Limited with creative tasks.\n",
    "- **Human**: The gold standard for subtle evaluations.\n",
    "- **Autoraters (LLM)**: Models that evaluate other models. Must be calibrated with human judgments for reliability.\n",
    "\n",
    "### **Advanced Evaluation**\n",
    "More interpretable systems are being developed, where an LLM breaks a task into subtasks and evaluates each, improving transparency and accuracy of judgment. Great for areas such as multimedia generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Speeding up inference in LLMs**\n",
    "\n",
    "As models grow, so do costs and latency. To optimize performance, we use:\n",
    "\n",
    "- **Trade-offs**: accepting small quality losses for speed or cost gains.\n",
    "- **Quantization**: reducing the precision of weights (e.g. from 32 to 4 bits), reducing latency and memory.\n",
    "- **Distillation**: a large model trains a smaller one to speed up inference.\n",
    "- **Flash Attention** and **Prefix Caching**: optimize attention and reuse computations for repeated inputs.\n",
    "- **Speculative Decoding**: a small model predicts tokens in advance and the main model verifies them.\n",
    "- **Batching and Parallelization**: processing multiple requests together and distributing the load across multiple hardware.\n",
    "\n",
    "These techniques improve efficiency while maintaining quality or only slightly sacrificing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Code and Math**\n",
    "- **LLM for Developers**: Generation, Completion, Refactoring, Translation, Testing, Documentation.\n",
    "- **AlphaCode 2**: Top 15% on Codeforces.\n",
    "- **FunSearch and AlphaGeometry**: Advanced Math Problem Solving.\n",
    "\n",
    "### **2. Machine Translation**\n",
    "- Natural translations in messaging, e-commerce, and travel apps.\n",
    "\n",
    "### **3. Text Summaries**\n",
    "- For news, scientific papers, business chats.\n",
    "\n",
    "### **4. Q&A**\n",
    "- Contextual and personalized answers in virtual assistants, customer support, and academic platforms.\n",
    "\n",
    "### **5. Chatbots**\n",
    "- Dynamic and human conversations in customer service and entertainment.\n",
    "\n",
    "### **6. Content Generation**\n",
    "- Advertisements, movie scripts, creative and coherent texts.\n",
    "\n",
    "### **7. Semantic Inference (NLI)**\n",
    "- Meaning analysis for sentiment, legal documents, and medical diagnoses.\n",
    "\n",
    "### **8. Text Classification**\n",
    "- Spam, news, customer feedback, evaluation of generated outputs.\n",
    "\n",
    "### **9. Text Analysis**\n",
    "- Market research, in-depth literature analysis.\n",
    "\n",
    "### **10. Multimodal Applications**\n",
    "- **Education, accessibility, medicine, marketing**: merging text, images, audio, and video for richer, smarter interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Whitepaper summary](https://www.kaggle.com/whitepaper-foundational-llm-and-text-generation):**\n",
    "\n",
    "- **Transformers**: the basis of all modern LLMs; not only the size of the model matters but also the quality of the data.\n",
    "- **Fine-tuning**: it is divided into multiple phases (e.g. instruction tuning, safety tuning, SFT, RLHF, RLAIF) to adapt the behavior of the model.\n",
    "- **Inference optimization**: there are techniques to reduce costs and latency without compromising performance.\n",
    "- **Applications**: LLMs can be used for summarization, translation, QA, chatbots, code generation and more.\n",
    "- **Prompt engineering & sampling**: fundamental to get relevant results; Top-K, Top-P and decoding parameters influence correctness, diversity and creativity.\n",
    "\n",
    "**Conclusion**: combining good fine-tuning, well-designed prompts and sampling techniques allows to get the most out of LLMs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
